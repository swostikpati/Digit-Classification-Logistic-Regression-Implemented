{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9ab16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "#tqdm attaches progress bars to iterable elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9b0c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and tranform datasets\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root = './datasets', train = True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './datasets', train = False, transform = transforms.ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4399bccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of testing samples : 10000\n"
     ]
    }
   ],
   "source": [
    "#display information about downloaded datasets\n",
    "print('Number of training samples: {}'.format(len(mnist_train)))\n",
    "print('Number of testing samples : {}'.format(len(mnist_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc1836cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default image shape: torch.Size([1, 28, 28])\n",
      "Reshaped image shape: torch.Size([28, 28])\n",
      "This image is labelled as: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at a data point\n",
    "image,label  = mnist_train[3] \n",
    "#4th image is that of '1'. The index can be between anywhere from 0 - 59999.\n",
    "#Each element in mnist_train constains a three dimensional numpy array.\n",
    "\n",
    "#reshaping - removing the grayscale\n",
    "print('Default image shape: {}'.format(image.shape))\n",
    "image = image.reshape([28,28])\n",
    "#this is neccessary in order for matplotlib to plot the image\n",
    "print('Reshaped image shape: {}'.format(image.shape))\n",
    "\n",
    "#plotting the image\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "#the grayscale is introduced again using cmap\n",
    "\n",
    "#displaying the label\n",
    "print('This image is labelled as: {}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c0fb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the data into mini batches\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size = 100 , shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size = 100 , shuffle = False)\n",
    "#print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b569d3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the minibatch of images: torch.Size([100, 1, 28, 28])\n",
      "Shape of the minibatch of labels: torch.Size([100])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([5, 9, 3, 5, 4, 1, 0, 3, 1, 1, 2, 2, 7, 7, 3, 9, 3, 8, 6, 2, 3, 3, 8, 3,\n",
      "        7, 9, 9, 0, 6, 0, 6, 1, 4, 7, 2, 3, 9, 4, 1, 3, 0, 0, 5, 1, 7, 4, 7, 3,\n",
      "        5, 3, 9, 5, 2, 9, 2, 5, 1, 2, 4, 8, 3, 7, 3, 2, 2, 5, 0, 1, 3, 5, 5, 2,\n",
      "        9, 9, 6, 7, 0, 5, 7, 1, 3, 0, 1, 2, 1, 3, 1, 9, 0, 4, 8, 0, 2, 1, 5, 9,\n",
      "        9, 7, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#An example of a minibatch\n",
    "#train_loader is a an object and hence is not iterable.\n",
    "#therefore an iterable variable is created and only one iteration is displayed\n",
    "#next() and iter() are used together to iterate through iterable objects.\n",
    "#next(iterable object, default) - default is printed when there are no more items in the iterable object.\n",
    "data_train_iter = iter(train_loader)\n",
    "images, labels = next(data_train_iter)\n",
    "print(\"Shape of the minibatch of images: {}\".format(images.shape))\n",
    "print(\"Shape of the minibatch of labels: {}\".format(labels.shape))\n",
    "print(images)\n",
    "print(labels)\n",
    "#If we iterate through the variable again a different set of data points and labels will be displayed.\n",
    "#images, labels = next(data_train_iter)\n",
    "#print(images)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69560229",
   "metadata": {},
   "source": [
    "Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b964e0",
   "metadata": {},
   "source": [
    "While our data inputs (which we'll call x) are images (i.e. 2-dimensional), MNIST digits are pretty small, and the model we're using is very simple. Thus, we're going to be treating the input as flat vectors. To convert our inputs into row vectors (a.k.a. flattening), we can use view(), the equivalent of NumPy's reshape().If there is any situation that you don't know how many rows you want but are sure of the number of columns, then you can specify this with a -1. (Note that you can extend this to tensors with more dimensions. Only one of the axis value can be -1). This is a way of telling the library: \"give me a tensor that has these many columns and you compute the appropriate number of rows that is necessary to make this happen\".\n",
    "\n",
    "Difference between view() and numpy.reshape()\n",
    "Unlike reshape, the new tensor returned by \"view\" shares the underlying data with the original tensor, so it is really a view into the old tensor instead of creating a brand new one. Reshape always copies memory. view never copies memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5fd4100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input x is: torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "#flattening out the data\n",
    "x = images.view(-1,28*28)\n",
    "print('The shape of input x is: {}'.format(x.shape))\n",
    "#This means there is a minibatch of 100 train sets each containing a single dimension flattened out array of 784 elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00366cf6",
   "metadata": {},
   "source": [
    "Matrix equation for logistic regression \n",
    "\n",
    "Y = XW + B\n",
    "\n",
    "m = size of minibatch = 100\n",
    "c = number of classes (0-9)  = 10\n",
    "d = dimension of flattened out matrix = 28 * 28 = 784\n",
    "\n",
    "Y = m * c;\n",
    "X = m * d;\n",
    "W = d * c;\n",
    "B = c * c;\n",
    "\n",
    "The weights are randomly initialised using the Xavier Initialisation - Multiply the randomly initialised weghts by 1/sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e2a8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation of weights and bias\n",
    "# The bias can be initialised as zero but the weights can't be as they are multiplied to the data vectors.\n",
    "\n",
    "W = torch.randn(784,10)/np.sqrt(784)\n",
    "#torch.randn(takes in the dimensions of the matrix). Each element of the matrix is a randomly generated number\n",
    "#np.sqrt() is same as math.sqrt() - it's just that we don't need to import the math module\n",
    "W.requires_grad_() \n",
    "\n",
    "B = torch.zeros(10,requires_grad = True)\n",
    "#torch.zeroes(dimension of the matrix) - generates a matrix of the given length with only zeroes.\n",
    "#setting requires_grad to true in both cases tells PyTorch's autograd to track the gradients for these two variables, and all the variables depending on W and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7f30b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equation\n",
    "y = torch.matmul(x,W) + B\n",
    "# x is the flattened out matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "961c0fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0270,  0.1676, -0.3097, -0.3453, -0.2312, -0.3693,  0.2840, -0.3461,\n",
      "         0.4263, -0.0346], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#raw prediction example\n",
    "print(y[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565f474",
   "metadata": {},
   "source": [
    "To calculate the loss function we first need to convert the raw prediction values into probabilities which sum up to one. This is done by using the softmax activation funtion.\n",
    "\n",
    "The softmax function is a function that turns a vector of K real values into a vector of K real values that sum to 1. It can be seen as an multi-class extension to the binary sigmoid.\n",
    "\n",
    "Difference between Sigmoid and Softmax:-\n",
    "Probabilities produced by a Sigmoid are independent. Furthermore, they are not constrained to sum to one.\n",
    "The outputs of a Softmax function are interrelated. The Softmax probabilities will always sum to one.If the likelihood of one class increases, the others decrease proportionately.\n",
    "\n",
    "Sigmoid function and signum function are not the same.\n",
    "\n",
    "Softmax function(yi) = exp(yi)/(summation from j=0 to j = c(exp(yj)))\n",
    "where c is the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce7f46d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_eq[0] from equation: tensor([0.1012, 0.1230, 0.0763, 0.0736, 0.0825, 0.0719, 0.1382, 0.0736, 0.1593,\n",
      "        0.1005], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Option 1 of implementing softmax (using equation)\n",
    "p_eq = torch.exp(y)/torch.sum(torch.exp(y), dim = 1, keepdim = True)\n",
    "print(\"p_eq[0] from equation: {}\".format(p_eq[0]))\n",
    "\n",
    "#dim is similar to axis in numpy... it determines the direction in which the sum has to take place. \n",
    "#keepdim is used to specify if the orginial dimensions are to be retained.\n",
    "#If dim = 0, the columns are summed up.\n",
    "#If dim = 1, the rows are summed up.\n",
    "#If keepdim = False - the sum is always displayed as a 1D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99d282f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p[0] from equation: tensor([0.1012, 0.1230, 0.0763, 0.0736, 0.0825, 0.0719, 0.1382, 0.0736, 0.1593,\n",
      "        0.1005], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Option 2 of implementing softmax (using direct softmax funtion offered by torch)\n",
    "import torch.nn.functional as F\n",
    "p = F.softmax(y, dim = 1)\n",
    "print(\"p[0] from equation: {}\".format(p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4628085d",
   "metadata": {},
   "source": [
    "Cross Entropy Loss function\n",
    "Actual formula is quite complex so directly use the implemented cross entropy function in the torch.nn.functional module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcbcdaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "cross entropy with torch.nn.functional.cross_entropy: 2.390179395675659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Note that PyTorch's cross-entropy loss combines the softmax operator and cross-entropy into a single operation, \\nfor numerical stability reasons. Don't do the softmax twice! Make sure to feed in the pre-softmax logits y,\\nnot the post-softmax probabilities py.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Implementing cross entropy\n",
    "print(labels.shape)\n",
    "#labels store the actual labels of the data\n",
    "cross_entropy = F.cross_entropy(y,labels)\n",
    "print(\"cross entropy with torch.nn.functional.cross_entropy: {}\".format(cross_entropy))\n",
    "\n",
    "'''Note that PyTorch's cross-entropy loss combines the softmax operator and cross-entropy into a single operation, \n",
    "for numerical stability reasons. Don't do the softmax twice! Make sure to feed in the pre-softmax logits y,\n",
    "not the post-softmax probabilities py.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df18081",
   "metadata": {},
   "source": [
    "The Backward Pass(Back propagation)\n",
    "We use the stochastic gradient descent as it works well with logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3cbf556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First all the variables(B and W) which require gradients are assigned gradients by using the backward() function\n",
    "#This has an enabled auto differentiation which computes(not assigns) gradients for each variable requiring one.\n",
    "cross_entropy.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b0e73b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0101, -0.0379, -0.0308, -0.0784,  0.0350, -0.0148,  0.0897, -0.0169,\n",
       "         0.0800, -0.0158])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The gradient computed for the bias.\n",
    "B.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8605678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The gradient computed for the weights - in this case the gradient turns out to be 0 for almost all the cases.\n",
    "W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "959321b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The inbuilt stocastic gradient descent available in pytorch is applied to create an optimizer \n",
    "#This would later assign the computed gradients.\n",
    "optimizer = torch.optim.SGD([W,B], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a652b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#The B before the gradient is assigned to B\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "301fb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning stochastic gradient descent to all the variables having computed gradient\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5bb163dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0010,  0.0038,  0.0031,  0.0078, -0.0035,  0.0015, -0.0090,  0.0017,\n",
      "        -0.0080,  0.0016], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#The Bias after backpropagation.\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The weight after backpropagation - in this case it remains unchanged as the weights had a gradient of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bc25ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The gradients keep on accumulating and hence it is neccessary to clear the gradients from the buffer after computing a mini batch.\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "014f5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "#The gradient of the bias is reset to 0.\n",
    "print(B.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0fd960",
   "metadata": {},
   "source": [
    "To train the model, we just need repeat what we just did for more minibatches from the training set. As a recap, the steps were:\n",
    "\n",
    "1.Draw a minibatch\n",
    "2.Zero the gradients in the buffers for W and b\n",
    "3.Perform the forward pass (compute prediction, calculate loss)\n",
    "4.Perform the backward pass (compute gradients, perform SGD step)\n",
    "\n",
    "Going through the entire dataset once is referred to as an epoch. In many cases, we train neural networks for multiple epochs, but here, a single epoch is enough. We also wrap the train_loader with tqdm. This isn't neccessary, but it adds a handy progress bar so we can track our training progress.\n",
    "In the training process all we need to do is determine W and B as accurately as possible by iterating through several mini batches. Then they are finally tested with the testing data and we try to determine the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51322221",
   "metadata": {},
   "source": [
    "THE TESTING PROCESS\n",
    "(Just the sample code)\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "#Autograd engine is turned of  is turned of which increases the speed of the iterations\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = torch.matmul(x, W) + b\n",
    "        \n",
    "        #y here is sort of a one-hot coding vector...so the index with the highest value \n",
    "        (confidence) will be the predicted digit. \n",
    "        \n",
    "        #torch.argmax() gives the  index of the highest value. dim = 1 refers to the x axis(rows)\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        \n",
    "        #the prediction is compared to the labels which correspond the current image. \n",
    "        #The labels also range from 0-9 just like the predictions which also range from (0-9) index.\n",
    "        \n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "        #.float() converts the values of 1 or 0 into floating point numbers which are then summed up...Just do it.\n",
    "        \n",
    "print('Test accuracy: {}'.format(correct/total))\n",
    "#The final test accuracy is obtained by dividing the total correct by the total data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15e454",
   "metadata": {},
   "source": [
    "THE ENTIRE CODE IN ONE GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0efa2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b3efb32014818a486c178dc9ad909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Over.\n",
      "\n",
      "Testing Phase...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39444756cc634880805f580337dc4a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Over.\n",
      "\n",
      "The accuracy of the logistic regression model is: 91.86000061035156 %\n"
     ]
    }
   ],
   "source": [
    "#Importing modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Loading the data\n",
    "mnist_train = datasets.MNIST(root = './datasets', train = True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = datasets.MNIST(root = './datasets', train = False, transform = transforms. ToTensor(), download = True)\n",
    "\n",
    "#Distributing the data\n",
    "train_batch = torch.utils.data.DataLoader(mnist_train, batch_size = 100, shuffle = True)\n",
    "test_batch = torch.utils.data.DataLoader(mnist_test, batch_size = 100, shuffle = False)\n",
    "\n",
    "#Initialising the parameters\n",
    "W = torch.randn(784,10)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "B = torch.zeros(10, requires_grad = True)\n",
    "\n",
    "#Creating the Optimizer - for weights and biases\n",
    "optimizer = torch.optim.SGD([W,B], lr = 0.7)\n",
    "\n",
    "#Training\n",
    "print('Traning Phase...')\n",
    "for images,labels in tqdm(train_batch):\n",
    "    #clear the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward pass\n",
    "    X = images.view(-1, 28*28)\n",
    "    Y = torch.matmul(X,W) + B\n",
    "    #Calculating loss\n",
    "    ce_loss = F.cross_entropy(Y,labels)\n",
    "    \n",
    "    #Backward pass\n",
    "    ce_loss.backward()\n",
    "    optimizer.step()\n",
    "print('Training Over.\\n')\n",
    "\n",
    "#Testing\n",
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "print('Testing Phase...')\n",
    "for image, label in tqdm(test_batch):\n",
    "    x = image.view(-1,28*28)\n",
    "    y = torch.matmul(x,W) + B\n",
    "    \n",
    "    pred = torch.argmax(y, dim = 1)\n",
    "    correct += torch.sum((pred == label).float())\n",
    "print('Testing Over.\\n')\n",
    "\n",
    "#Calculating accuracy\n",
    "print('The accuracy of the logistic regression model is: {} %'.format(correct*100/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fef0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
